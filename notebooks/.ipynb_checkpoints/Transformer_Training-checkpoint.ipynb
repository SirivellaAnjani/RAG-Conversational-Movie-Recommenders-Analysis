{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f546f2fa-7677-4ef7-8c0f-8af1620eeeb4",
   "metadata": {},
   "source": [
    "# Training Transformer Recommender on INSPIRED Dataset\n",
    "\n",
    "This notebook trains the Transformer-based movie recommender on the INSPIRED dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2113361b-8f64-4108-ae20-cb35bb2abb7d",
   "metadata": {},
   "source": [
    "## Environmental Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1290935e-6700-47fa-b8da-8786eb5a4065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root: C:\\Users\\91953\\Documents\\GitHub\\RAG-Movie-CRS\n",
      "Current Working Directory: C:\\Users\\91953\\Documents\\GitHub\\RAG-Movie-CRS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(\"..\")\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = os.getcwd()\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Check current directory\n",
    "current_directory = os.getcwd()\n",
    "print(\"Project Root:\", project_root)\n",
    "print(\"Current Working Directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c48e6bb7-9f2a-4bb7-87d7-7f8441dcfc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import your transformer model\n",
    "from scripts.transformer_recommender import TransformerRecommender, INSPIREDDataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03d47244-8b03-4ccf-abfe-d87411d8281b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1+cpu\n",
      "CUDA available: False\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e04be16-4e70-465d-8b6b-b1f7f2a4c577",
   "metadata": {},
   "source": [
    "## DATA PREPARATION FOR TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f183a4e-3e16-4111-b152-decc1f6e62d3",
   "metadata": {},
   "source": [
    "### Load Dataset And Create Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7760b026-9b0a-43e4-9b8c-5e5d1621d1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data processor\n",
    "data_processor = INSPIREDDataProcessor(dataset_dir=\"data\")\n",
    "\n",
    "# Load movie database\n",
    "print(\"Loading movie database...\")\n",
    "movie_id_map, movie_name_map = data_processor.load_movie_database()\n",
    "\n",
    "print(f\"\\nTotal movies in database: {len(movie_id_map)}\")\n",
    "\n",
    "# Load dialogs\n",
    "print(\"\\nLoading dialogs...\")\n",
    "train_dialogs = data_processor.load_dialogs(split=\"train\", max_dialogs=None)\n",
    "val_dialogs = data_processor.load_dialogs(split=\"dev\", max_dialogs=None)\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"Training: {len(train_dialogs)} dialogs\")\n",
    "print(f\"Validation: {len(val_dialogs)} dialogs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06196d8-6bc7-4a07-8fb7-c790ea5ec9fd",
   "metadata": {},
   "source": [
    "### PyTorch Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadda0c6-3c2a-462f-91e0-1a507a895a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieRecommendationDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for INSPIRED movie conversations\"\"\"\n",
    "    \n",
    "    def __init__(self, dialogs, num_movies, tokenizer, max_length=512):\n",
    "        self.dialogs = dialogs\n",
    "        self.num_movies = num_movies\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dialogs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dialog = self.dialogs[idx]\n",
    "        \n",
    "        # Tokenize conversation\n",
    "        encoding = self.tokenizer(\n",
    "            dialog['conversation'],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Create multi-hot label vector (1 for recommended movies, 0 for others)\n",
    "        labels = torch.zeros(self.num_movies, dtype=torch.float)\n",
    "        for movie_id in dialog['recommended_movies']:\n",
    "            if movie_id < self.num_movies:\n",
    "                labels[movie_id] = 1.0\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "print(\"MovieRecommendationDataset class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cbca0d-92e9-45e2-b1fe-583c066ea3f8",
   "metadata": {},
   "source": [
    "### CREATE DATASETS AND DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e66777-06ef-48b7-adc8-2cd3f1f0ea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = MovieRecommendationDataset(\n",
    "    train_dialogs, \n",
    "    len(movie_id_map), \n",
    "    tokenizer,\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "val_dataset = MovieRecommendationDataset(\n",
    "    val_dialogs, \n",
    "    len(movie_id_map), \n",
    "    tokenizer,\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 8  # Adjust based on your GPU memory\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0  # Set to 0 for Windows\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"Created dataloaders:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Batch size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca16628e-2620-4e92-bd78-318e8baa0751",
   "metadata": {},
   "source": [
    "### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6382bd0-ec40-4a41-ba1c-ec31a1f3027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerRecommender(\n",
    "    model_name=\"bert-base-uncased\",\n",
    "    num_movies=len(movie_id_map)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Model initialized:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848b3e94-11d7-41b4-b220-9e0e2d884bd4",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5407a46-4149-4e11-95e5-f1034cd9d076",
   "metadata": {},
   "source": [
    "### Training Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81bfbda-c98d-46b6-a253-0d090614fda6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dce1c1-2844-4e3d-a16e-7df9a9391f27",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7692216f-6559-4fcc-b069-050b696d7ba7",
   "metadata": {},
   "source": [
    "### Save/Load Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3923b432-4645-4ee7-9fc0-29fefe7fb5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
